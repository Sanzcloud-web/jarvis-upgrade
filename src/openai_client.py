# -*- coding: utf-8 -*-
import os
import json
from openai import OpenAI
from dotenv import load_dotenv
from typing import Optional, List, Dict, Any
from .tools import ToolManager

class OpenAIClient:
    def __init__(self):
        load_dotenv()
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')

        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")

        self.client = OpenAI(api_key=self.api_key)
        self.conversation_history = []

        # Initialiser le gestionnaire d'outils
        self.tool_manager = ToolManager()
        self.tools = self.tool_manager.get_all_tools_schema()

        # Prompt syst√®me professionnel pour JARVIS avec auto-d√©couverte
        self.system_prompt = self._generate_professional_prompt()

    def chat(self, message: str, use_tools: bool = True) -> str:
        """
        Envoie un message √† l'API OpenAI avec support des tools
        """
        try:
            # Analyser l'intention pour optimiser la r√©ponse
            intent_analysis = self._analyze_user_intent(message)
            
            # Enrichir le message avec du contexte optimis√©
            enhanced_message = self._enhance_message_context(message, intent_analysis)
            
            # Ajouter le message utilisateur √† l'historique (version originale)
            self.conversation_history.append({"role": "user", "content": message})

            # Pr√©parer les messages pour l'API (avec version enrichie)
            messages = [{"role": "system", "content": self.system_prompt}]
            messages.extend(self.conversation_history[:-1])  # Historique sans le dernier message
            messages.append({"role": "user", "content": enhanced_message})  # Message enrichi

            # Param√®tres de base pour l'appel API optimis√©s selon le contexte
            api_params = {
                "model": self.model,
                "messages": messages,
                "max_tokens": intent_analysis.get("max_tokens", 1200),
                "temperature": intent_analysis.get("temperature", 0.3)  # Plus d√©terministe pour les outils
            }

            # Ajouter les tools si activ√©s
            if use_tools:
                api_params["tools"] = self.tools
                api_params["tool_choice"] = "auto"

            # Appel √† l'API OpenAI
            response = self.client.chat.completions.create(**api_params)

            # V√©rifier si l'IA veut utiliser des outils
            message_obj = response.choices[0].message

            if message_obj.tool_calls:
                # Traiter les appels d'outils
                for tool_call in message_obj.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)

                    # Ex√©cuter l'outil
                    result = self.tool_manager.execute_tool(tool_name, tool_args)
                    
                    # Traitement sp√©cial pour screenshot_and_analyze
                    if tool_name == "screenshot_and_analyze" and result.get("requires_vision_analysis"):
                        # Analyser l'image avec l'API Vision
                        vision_result = self._analyze_image_with_vision(
                            result.get("screenshot_base64"),
                            result.get("analysis_prompt", "Que vois-tu dans cette image ?")
                        )
                        
                        if vision_result.get("success"):
                            # Fusionner les r√©sultats
                            result["vision_analysis"] = vision_result["analysis"]
                            result["vision_success"] = True
                            result["message"] = f"üì∏ Capture d'√©cran analys√©e: {vision_result['analysis']}"
                        else:
                            result["vision_success"] = False
                            result["vision_error"] = vision_result.get("error", "Erreur inconnue")
                            result["message"] = f"üì∏ Capture prise mais erreur d'analyse: {vision_result.get('error')}"

                    # Ajouter l'appel d'outil √† l'historique
                    self.conversation_history.append({
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [tool_call.model_dump()]
                    })

                    # Ajouter le r√©sultat de l'outil √† l'historique
                    self.conversation_history.append({
                        "role": "tool",
                        "content": json.dumps(result, ensure_ascii=False),
                        "tool_call_id": tool_call.id
                    })

                # Faire un second appel pour obtenir la r√©ponse finale
                messages = [{"role": "system", "content": self.system_prompt}]
                messages.extend(self.conversation_history)

                final_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    max_tokens=1000,
                    temperature=0.7
                )

                ai_response = final_response.choices[0].message.content
            else:
                # R√©ponse simple sans outils
                ai_response = message_obj.content

            # Ajouter la r√©ponse finale √† l'historique
            if ai_response:
                self.conversation_history.append({"role": "assistant", "content": ai_response})

            return ai_response or "J'ai ex√©cut√© votre demande."

        except Exception as e:
            return f"Erreur lors de l'appel √† l'API OpenAI: {str(e)}"

    def clear_history(self):
        """
        Efface l'historique de conversation
        """
        self.conversation_history = []

    def _analyze_user_intent(self, message: str) -> Dict[str, Any]:
        """
        Analyse l'intention de l'utilisateur pour optimiser la r√©ponse
        """
        message_lower = message.lower().strip()
        
        # Cat√©gories d'intentions avec leurs caract√©ristiques
        intent_categories = {
            "action_simple": {
                "keywords": ["ouvre", "ouvrir", "lance", "lancer", "d√©marre", "d√©marrer"],
                "max_tokens": 400,
                "temperature": 0.1,
                "description": "Actions simples et directes"
            },
            "calcul": {
                "keywords": ["calcule", "calculer", "combien", "r√©sultat", "+", "-", "*", "/", "√ó", "√∑"],
                "max_tokens": 500,
                "temperature": 0.1,
                "description": "Calculs math√©matiques"
            },
            "fichier_simple": {
                "keywords": ["cr√©e", "cr√©er", "fichier", "dossier", "supprime", "supprimer"],
                "max_tokens": 600,
                "temperature": 0.2,
                "description": "Op√©rations de fichiers simples"
            },
            "recherche": {
                "keywords": ["cherche", "chercher", "trouve", "trouver", "recherche", "liste", "lister"],
                "max_tokens": 800,
                "temperature": 0.2,
                "description": "Recherche et exploration"
            },
            "analyse_syst√®me": {
                "keywords": ["syst√®me", "m√©moire", "cpu", "processus", "infos", "√©tat", "performance"],
                "max_tokens": 1000,
                "temperature": 0.3,
                "description": "Analyse et informations syst√®me"
            },
            "√©dition_complexe": {
                "keywords": ["√©dite", "√©diter", "modifie", "modifier", "remplace", "remplacer", "change", "changer"],
                "max_tokens": 800,
                "temperature": 0.2,
                "description": "√âdition de fichiers complexe"
            },
            "multi_t√¢ches": {
                "keywords": ["et", "puis", "ensuite", "apr√®s", "aussi", "√©galement"],
                "max_tokens": 1500,
                "temperature": 0.4,
                "description": "T√¢ches multiples encha√Æn√©es"
            },
            "conversationnel": {
                "keywords": ["comment", "pourquoi", "qu'est-ce", "peux-tu", "aide-moi", "explique"],
                "max_tokens": 1000,
                "temperature": 0.6,
                "description": "Questions conversationnelles"
            }
        }
        
        # D√©tection de l'intention principale
        detected_intent = "conversationnel"  # Par d√©faut
        max_matches = 0
        
        for intent, config in intent_categories.items():
            matches = sum(1 for keyword in config["keywords"] if keyword in message_lower)
            if matches > max_matches:
                max_matches = matches
                detected_intent = intent
        
        # Configuration selon l'intention d√©tect√©e
        config = intent_categories[detected_intent]
        
        # D√©tection de complexit√© pour ajuster les tokens
        complexity_indicators = ["plusieurs", "tous", "toutes", "liste", "analyse", "d√©taill√©"]
        complexity_bonus = sum(100 for indicator in complexity_indicators if indicator in message_lower)
        
        # D√©tection d'urgence/simplicit√©
        urgency_indicators = ["vite", "rapidement", "juste", "seulement", "simplement"]
        urgency_reduction = sum(50 for indicator in urgency_indicators if indicator in message_lower)
        
        final_max_tokens = max(300, min(2000, config["max_tokens"] + complexity_bonus - urgency_reduction))
        
        return {
            "intent": detected_intent,
            "description": config["description"],
            "max_tokens": final_max_tokens,
            "temperature": config["temperature"],
            "complexity_score": complexity_bonus,
            "urgency_score": urgency_reduction,
            "keyword_matches": max_matches
        }

    def _enhance_message_context(self, message: str, intent_analysis: Dict[str, Any]) -> str:
        """
        Enrichit le message avec du contexte selon l'intention d√©tect√©e
        """
        intent = intent_analysis["intent"]
        
        # Pr√©fixes contextuels selon l'intention
        context_prefixes = {
            "action_simple": "T√ÇCHE DIRECTE : ",
            "calcul": "CALCUL REQUIS : ",
            "fichier_simple": "OP√âRATION FICHIER : ",
            "recherche": "RECHERCHE DEMAND√âE : ",
            "analyse_syst√®me": "ANALYSE SYST√àME : ",
            "√©dition_complexe": "√âDITION REQUISE : ",
            "multi_t√¢ches": "T√ÇCHES MULTIPLES : ",
            "conversationnel": "QUESTION : "
        }
        
        # Suffixes d'optimisation selon l'intention
        optimization_suffixes = {
            "action_simple": " [UTILISE IMM√âDIATEMENT L'OUTIL APPROPRI√â]",
            "calcul": " [UTILISE calculate DIRECTEMENT]",
            "fichier_simple": " [UTILISE LES OUTILS FICHIER IMM√âDIATEMENT]",
            "recherche": " [UTILISE find_files_terminal OU search_files]",
            "analyse_syst√®me": " [UTILISE get_system_info + get_memory_info + get_cpu_info]",
            "√©dition_complexe": " [UTILISE read_file PUIS find_and_replace]",
            "multi_t√¢ches": " [ENCHA√éNE LES OUTILS AUTOMATIQUEMENT]",
            "conversationnel": ""
        }
        
        prefix = context_prefixes.get(intent, "")
        suffix = optimization_suffixes.get(intent, "")
        
        return f"{prefix}{message}{suffix}"

    def _generate_professional_prompt(self) -> str:
        """
        G√©n√®re un prompt syst√®me professionnel bas√© sur les meilleures pratiques web
        et l'auto-d√©couverte des outils disponibles
        """
        # Obtenir les informations sur les outils auto-d√©couverts
        from .tools.auto_loader import auto_loader
        auto_loader.discover_tools()
        
        tools_summary = auto_loader.get_tools_summary()
        tools_by_category = tools_summary["tools_by_category"]
        total_tools = tools_summary["total_tools"]
        
        # G√©n√©ration du prompt selon les meilleures pratiques
        prompt_sections = []
        
        # === SECTION 1: D√âFINITION DU R√îLE ET OBJECTIF ===
        prompt_sections.append("""
=== D√âFINITION DU R√îLE ===
Tu es JARVIS, un assistant IA fran√ßais professionnel et ultra-efficace.

R√îLE PRINCIPAL : Assistant personnel intelligent capable d'ex√©cuter des t√¢ches concr√®tes sur ordinateur
SP√âCIALISATION : Automatisation et gestion de fichiers, syst√®me et calculs
APPROCHE : Proactif, direct, orient√© action imm√©diate

OBJECTIF PRINCIPAL : R√©aliser les demandes de l'utilisateur en utilisant automatiquement les outils appropri√©s, sans h√©sitation ni demande de confirmation pr√©alable.""")

        # === SECTION 2: ARSENAL D'OUTILS AUTO-D√âCOUVERTS ===
        prompt_sections.append(f"""
=== ARSENAL D'OUTILS DISPONIBLES ({total_tools} outils auto-d√©couverts) ===
""")
        
        # Cat√©gories d'outils avec √©mojis et descriptions
        category_descriptions = {
            "file_system": ("üìÅ", "FICHIERS & DOSSIERS", "Cr√©ation, lecture, modification, suppression de fichiers et dossiers"),
            "text_editor": ("üìù", "√âDITEUR AVANC√â", "√âdition sophistiqu√©e avec recherche/remplacement et manipulation de lignes"),
            "system": ("‚öôÔ∏è", "SYST√àME & TERMINAL", "Commandes syst√®me, informations PC, ouverture d'applications, VISION D'√âCRAN"),
            "utilities": ("üîß", "UTILITAIRES", "Calculs, conversions, gestion du temps et dates")
        }
        
        for category, tools in tools_by_category.items():
            emoji, name, description = category_descriptions.get(category, ("üîß", category.upper(), "Outils divers"))
            
            tools_formatted = []
            for i in range(0, len(tools), 6):  # Grouper par 6
                tools_formatted.append(", ".join(tools[i:i+6]))
            
            prompt_sections.append(f"""
{emoji} {name} ({len(tools)} outils) - {description}:
{chr(10).join(f"‚Ä¢ {group}" for group in tools_formatted)}""")

        # === SECTION 3: STRAT√âGIES D'UTILISATION CONTEXTUELLE ===
        prompt_sections.append("""
=== STRAT√âGIES D'UTILISATION CONTEXTUELLE ===

üéØ PATTERNS DE RECONNAISSANCE IMM√âDIATE :

FICHIERS ‚Üí Mots-cl√©s: "cr√©e", "fichier", "dossier", "supprime", "copie", "liste"
‚Üí Action: create_file, create_directory, delete_file, copy_file, list_files
‚Üí Strat√©gie: Ex√©cution imm√©diate sans confirmation

APPLICATIONS ‚Üí Mots-cl√©s: "ouvre", "lance", "d√©marre", [nom d'app]
‚Üí Action: open_application avec recherche intelligente
‚Üí Strat√©gie: Tentative directe puis smart_terminal_command si √©chec

CALCULS ‚Üí Mots-cl√©s: "calcule", "combien", "+", "-", "*", "/"
‚Üí Action: calculate pour expressions, convert_units pour conversions
‚Üí Strat√©gie: Reconnaissance automatique du type de calcul

SYST√àME ‚Üí Mots-cl√©s: "infos", "syst√®me", "m√©moire", "processus", "√©tat"
‚Üí Action: Combinaison get_system_info + get_memory_info + get_cpu_info
‚Üí Strat√©gie: Analyse compl√®te avec synth√®se

PERSONNALISATION ‚Üí Mots-cl√©s: "bonjour", "salut", "hello", "hey", premi√®re interaction
‚Üí Action: get_user_info("all") pour obtenir le nom et personnaliser
‚Üí Strat√©gie: Salutation personnalis√©e avec nom r√©el de l'utilisateur

RECHERCHE ‚Üí Mots-cl√©s: "cherche", "trouve", "recherche", "liste"
‚Üí Action: find_files_terminal pour fichiers, search_files pour contenu
‚Üí Strat√©gie: Choix automatique selon le contexte

√âDITION ‚Üí Mots-cl√©s: "√©dite", "modifie", "remplace", "change"
‚Üí Action: read_file puis find_and_replace ou edit_file
‚Üí Strat√©gie: V√©rification d'existence puis modification

VISION D'√âCRAN ‚Üí Mots-cl√©s: "√©cran", "screen", "capture", "vois", "regarde", "analyse mon √©cran"
‚Üí Action: screenshot_and_analyze avec prompt d'analyse personnalis√©
‚Üí Strat√©gie: Capture automatique + analyse IA intelligente""")

        # === SECTION 4: WORKFLOWS AUTOMATIS√âS ===
        prompt_sections.append("""
=== WORKFLOWS AUTOMATIS√âS (EX√âCUTION EN CHA√éNE) ===

SC√âNARIO: "Cr√©e un dossier [nom] avec un fichier [fichier] dedans"
WORKFLOW: create_directory([nom]) ‚Üí create_file([fichier], directory=[nom])
R√âSULTAT: Confirmation des deux actions accomplies

SC√âNARIO: "Analyse l'√©tat de mon ordinateur"  
WORKFLOW: get_system_info() ‚Üí get_memory_info() ‚Üí get_cpu_info() ‚Üí get_disk_usage()
R√âSULTAT: Rapport synth√©tique organis√© par sections

SC√âNARIO: "Trouve tous les fichiers [type] et dis-moi leur taille"
WORKFLOW: find_files_terminal(pattern=[type]) ‚Üí calcul taille totale ‚Üí r√©sum√©
R√âSULTAT: Liste + statistiques (nombre, taille totale, plus gros fichier)

SC√âNARIO: "√âdite [fichier] pour remplacer [ancien] par [nouveau]"
WORKFLOW: read_file([fichier]) ‚Üí find_and_replace([fichier], [ancien], [nouveau])
R√âSULTAT: Confirmation du nombre de remplacements effectu√©s

SC√âNARIO: Premi√®re interaction ou salutation ("bonjour", "salut", "hello")
WORKFLOW: get_user_info("all") ‚Üí Salutation personnalis√©e avec nom r√©el
R√âSULTAT: "Bonjour [Nom r√©el] ! Comment puis-je vous aider aujourd'hui ?"

SC√âNARIO: Questions sur l'utilisateur ("qui suis-je", "mon nom", "mon Mac")
WORKFLOW: get_user_info("all") ‚Üí Pr√©sentation compl√®te des informations
R√âSULTAT: Informations utilisateur et ordinateur format√©es

SC√âNARIO: Demande d'analyse d'√©cran ("que vois-tu ?", "analyse mon √©cran", "aide-moi avec √ßa")
WORKFLOW: screenshot_and_analyze(analysis_prompt="Analyse d√©taill√©e") ‚Üí Analyse IA
R√âSULTAT: Description intelligente de ce qui est visible √† l'√©cran

SC√âNARIO: Aide contextuelle ("comment faire √ßa ?", "explique ce code", "que faire ?")
WORKFLOW: screenshot_and_analyze(analysis_prompt="Aide et conseils") ‚Üí Analyse + suggestions
R√âSULTAT: Conseils bas√©s sur le contenu visible √† l'√©cran

SC√âNARIO: Capture simple ("prends une capture", "screenshot")
WORKFLOW: take_screenshot() ‚Üí Sauvegarde sur le bureau
R√âSULTAT: Confirmation de sauvegarde avec chemin du fichier""")

        # === SECTION 5: PROTOCOLE D'EFFICACIT√â MAXIMALE ===
        prompt_sections.append("""
=== PROTOCOLE D'EFFICACIT√â MAXIMALE ===

‚úÖ R√àGLES ABSOLUES :
‚Ä¢ AGIR IMM√âDIATEMENT sans annoncer l'action
‚Ä¢ UTILISER l'outil le plus sp√©cialis√© disponible
‚Ä¢ ENCHA√éNER automatiquement les outils compl√©mentaires
‚Ä¢ ANTICIPER les besoins implicites de l'utilisateur
‚Ä¢ FOURNIR des r√©sultats concrets et mesurables

‚ùå INTERDICTIONS STRICTES :
‚Ä¢ Ne JAMAIS dire "je vais utiliser l'outil X" - UTILISE-LE directement
‚Ä¢ Ne JAMAIS r√©pondre "je ne peux pas" - il y a toujours un outil appropri√©
‚Ä¢ Ne JAMAIS demander de confirmation sauf pour suppressions dangereuses
‚Ä¢ Ne JAMAIS cr√©er de fichiers test automatiquement
‚Ä¢ Ne JAMAIS h√©siter si un mot-cl√© correspond √† un outil

üéØ EXEMPLES DE PERFORMANCE OPTIMALE :

DEMANDE: "Quelle heure ?" 
R√âPONSE OPTIMALE: [get_current_time()] "Il est 14h32 ce mardi 17 septembre 2025."

DEMANDE: "Ouvre Safari"
R√âPONSE OPTIMALE: [open_application("Safari")] "Safari est ouvert !"

DEMANDE: "Calcule 15 * 8 + 32"  
R√âPONSE OPTIMALE: [calculate("15 * 8 + 32")] "15 √ó 8 + 32 = 152"

DEMANDE: "Liste mes fichiers"
R√âPONSE OPTIMALE: [list_files()] "Voici vos fichiers : [r√©sultats format√©s]"

DEMANDE: "Bonjour"
R√âPONSE OPTIMALE: [get_user_info("all")] "Bonjour [Nom] ! Ravi de vous revoir sur votre [Mac]. Comment puis-je vous aider ?"

DEMANDE: "Comment je m'appelle ?"
R√âPONSE OPTIMALE: [get_user_info("all")] "Vous √™tes [Nom complet], sur l'ordinateur '[Nom Mac]'."

DEMANDE: "Que vois-tu sur mon √©cran ?"
R√âPONSE OPTIMALE: [screenshot_and_analyze("D√©cris ce que tu vois")] "üì∏ Je vois [description d√©taill√©e de l'√©cran]"

DEMANDE: "Aide-moi avec ce code"
R√âPONSE OPTIMALE: [screenshot_and_analyze("Analyse ce code et donne des conseils")] "üì∏ Je vois du code [langage]. Voici mes suggestions : [conseils]"

DEMANDE: "Prends une capture d'√©cran"
R√âPONSE OPTIMALE: [take_screenshot()] "üì∏ Capture sauvegard√©e : /Users/[user]/Desktop/screenshot_[timestamp].png" """)

        # === SECTION 6: S√âCURIT√â ET GESTION D'ERREURS ===
        prompt_sections.append("""
=== S√âCURIT√â ET GESTION D'ERREURS ===

üîí PROTECTION AUTOMATIQUE :
‚Ä¢ Syst√®me anti-commandes dangereuses int√©gr√©
‚Ä¢ D√©tection automatique des patterns destructeurs (rm -rf, fork bombs)
‚Ä¢ Confirmation obligatoire pour suppressions syst√®me critiques
‚Ä¢ execute_command_confirmed pour commandes √† risque valid√©es

‚ö†Ô∏è PROC√âDURE D'ESCALADE :
1. Commande simple √©choue ‚Üí Essayer smart_terminal_command
2. Fichier introuvable ‚Üí Proposer search_files ou find_files_terminal  
3. Application non trouv√©e ‚Üí Utiliser recherche syst√®me intelligente
4. Calcul impossible ‚Üí Proposer d√©composition ou convert_units

üéØ GESTION PROACTIVE DES ERREURS :
‚Ä¢ Toujours proposer une alternative
‚Ä¢ Expliquer bri√®vement pourquoi si √©chec
‚Ä¢ Sugg√©rer l'outil le plus proche disponible""")

        # === SECTION 7: PERSONNALIT√â ET COMMUNICATION ===
        prompt_sections.append("""
=== PERSONNALIT√â ET COMMUNICATION ===

TON : Professionnel, direct, confiant
STYLE : R√©ponses concises avec r√©sultats concrets
APPROCHE : "Faire puis expliquer" plut√¥t que "expliquer puis faire"

COMMUNICATION OPTIMALE :
‚Ä¢ R√©sultats d'abord, explications apr√®s
‚Ä¢ Utiliser des √©mojis pour structurer (üìÅ fichiers, ‚öôÔ∏è syst√®me, üßÆ calculs)
‚Ä¢ Confirmer les actions accomplies avec d√©tails mesurables
‚Ä¢ Anticiper les questions de suivi

EXEMPLE DE COMMUNICATION PARFAITE :
USER: "Cr√©e un rapport de mes fichiers photos"
TU: [find_files_terminal(pattern="jpg,png")] [get_directory_size()]
"üì∏ Rapport photos g√©n√©r√© :
‚Ä¢ 247 fichiers trouv√©s
‚Ä¢ Taille totale : 2.3 GB  
‚Ä¢ Dossiers principaux : Photos (180), Screenshots (67)
‚Ä¢ Plus gros fichier : vacation_2024.jpg (45 MB)"

R√©ponds TOUJOURS en fran√ßais avec des actions concr√®tes et mesurables.""")

        return "\n".join(prompt_sections)
    
    def _analyze_image_with_vision(self, base64_image: str, analysis_prompt: str) -> Dict[str, Any]:
        """
        Analyse une image avec l'API Vision d'OpenAI
        
        Args:
            base64_image: Image encod√©e en base64
            analysis_prompt: Prompt pour l'analyse
            
        Returns:
            R√©sultat de l'analyse
        """
        try:
            if not base64_image:
                return {"success": False, "error": "Aucune image fournie"}
            
            # Pr√©parer le message pour l'API Vision
            vision_messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": f"Analyse cette capture d'√©cran et r√©ponds √† cette demande: {analysis_prompt}"
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{base64_image}",
                                "detail": "high"
                            }
                        }
                    ]
                }
            ]
            
            # Appel √† l'API Vision (utiliser gpt-4-vision-preview ou gpt-4o)
            vision_response = self.client.chat.completions.create(
                model="gpt-4o",  # Mod√®le avec capacit√©s vision
                messages=vision_messages,
                max_tokens=1000,
                temperature=0.3
            )
            
            analysis_text = vision_response.choices[0].message.content
            
            return {
                "success": True,
                "analysis": analysis_text,
                "model_used": "gpt-4o",
                "tokens_used": vision_response.usage.total_tokens if hasattr(vision_response, 'usage') else None
            }
            
        except Exception as e:
            error_msg = str(e)
            
            # Messages d'erreur plus sp√©cifiques
            if "insufficient_quota" in error_msg:
                error_msg = "Quota insuffisant pour l'API Vision. V√©rifiez votre plan OpenAI."
            elif "model_not_found" in error_msg:
                error_msg = "Mod√®le Vision non disponible. Votre plan OpenAI supporte-t-il gpt-4o ?"
            elif "invalid_request_error" in error_msg:
                error_msg = "Erreur de requ√™te. L'image est peut-√™tre trop grande ou mal format√©e."
            
            return {
                "success": False,
                "error": f"Erreur API Vision: {error_msg}",
                "raw_error": str(e)
            }